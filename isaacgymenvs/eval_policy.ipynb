{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "715985bf-55f7-4d7c-bb65-dbb1054dbb37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T14:38:02.530267Z",
     "iopub.status.busy": "2022-07-14T14:38:02.529979Z",
     "iopub.status.idle": "2022-07-14T14:38:04.678872Z",
     "shell.execute_reply": "2022-07-14T14:38:04.678215Z",
     "shell.execute_reply.started": "2022-07-14T14:38:02.530191Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing module 'gym_37' (/scr-ssd/ksrini/Downloads/isaacgym/python/isaacgym/_bindings/linux-x86_64/gym_37.so)\n",
      "Setting GYM_USD_PLUG_INFO_PATH to /scr-ssd/ksrini/Downloads/isaacgym/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json\n",
      "PyTorch version 1.8.1\n",
      "Device count 1\n",
      "/scr-ssd/ksrini/Downloads/isaacgym/python/isaacgym/_bindings/src/gymtorch\n",
      "Using /afs/cs.stanford.edu/u/ksrini/.cache/torch_extensions as PyTorch extensions root...\n",
      "Emitting ninja build file /afs/cs.stanford.edu/u/ksrini/.cache/torch_extensions/gymtorch/build.ninja...\n",
      "Building extension module gymtorch...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module gymtorch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 07:38:04,547 - INFO - logger - logger initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: FBX library failed to load - importing FBX data will not succeed. Message: No module named 'fbx'\n",
      "FBX tools must be installed from https://help.autodesk.com/view/FBX/2020/ENU/?guid=FBX_Developer_Help_scripting_with_python_fbx_installing_python_fbx_html\n"
     ]
    }
   ],
   "source": [
    "from isaacgym import gymtorch, gymapi\n",
    "from isaacgymenvs import train\n",
    "from rl_games.torch_runner import Runner\n",
    "from hydra import compose, initialize\n",
    "from rl_games.common import env_configurations, vecenv\n",
    "from isaacgymenvs.utils.rlgames_utils import RLGPUEnv, RLGPUTaskAlgoObserver, get_rlgames_env_creator\n",
    "from rl_games.algos_torch import model_builder\n",
    "from isaacgymenvs.learning import common_player\n",
    "from isaacgymenvs.utils.reformat import omegaconf_to_dict\n",
    "\n",
    "import isaacgymenvs\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "os.environ['DISPLAY'] = \":5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec268b-88ce-4913-9526-bd799648ef96",
   "metadata": {},
   "source": [
    "## Initialize config and defining builder helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da04fe59-0e2e-472b-8b59-3682a5ded48e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T14:38:04.680674Z",
     "iopub.status.busy": "2022-07-14T14:38:04.680474Z",
     "iopub.status.idle": "2022-07-14T14:38:05.007924Z",
     "shell.execute_reply": "2022-07-14T14:38:05.007304Z",
     "shell.execute_reply.started": "2022-07-14T14:38:04.680653Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scr1/.pyenv/versions/miniconda3-latest/envs/rlgpu/lib/python3.7/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/scr1/.pyenv/versions/miniconda3-latest/envs/rlgpu/lib/python3.7/site-packages/hydra/_internal/defaults_list.py:413: UserWarning: In config: Invalid overriding of hydra/job_logging:\n",
      "Default list overrides requires 'override' keyword.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/defaults_list_override for more information.\n",
      "\n",
      "  deprecation_warning(msg)\n"
     ]
    }
   ],
   "source": [
    "with initialize(config_path=\"cfg\", job_name=\"test_env\"):\n",
    "    cfg = compose(config_name=\"config\", overrides=[\"task=AllegroHandGrasp\", \n",
    "                                                   \"task.env.observationType=full\",\n",
    "                                                   # \"task.env.objectType=spray_bottle\",\n",
    "                                                   # \"sim_device=cpu\",\n",
    "                                                   \"experiment=scaled-ac\",\n",
    "                                                   \"headless=true\",\n",
    "                                                   \"test=true\",\n",
    "                                                   \"task.env.useRelativeControl=true\",\n",
    "                                                   \"checkpoint=./runs/scaled-ac/nn/scaled-ac.pth\",\n",
    "                                                   \"num_envs=64\"])\n",
    "\n",
    "\n",
    "def create_env_thunk(**kwargs):\n",
    "        envs = isaacgymenvs.make(cfg.seed, cfg.task_name, cfg.task.env.numEnvs, \n",
    "            cfg.sim_device, cfg.rl_device, cfg.graphics_device_id, cfg.headless,\n",
    "            cfg.multi_gpu, cfg.capture_video, cfg.force_render, cfg,\n",
    "            **kwargs,\n",
    "        )\n",
    "        if cfg.capture_video:\n",
    "            envs.is_vector_env = True\n",
    "            envs = gym.wrappers.RecordVideo(\n",
    "                envs,\n",
    "                f\"videos/{run_name}\",\n",
    "                step_trigger=lambda step: step % cfg.capture_video_freq == 0,\n",
    "                video_length=cfg.capture_video_len,\n",
    "            ) \n",
    "        return envs\n",
    "\n",
    "# register new AMP network builder and agent\n",
    "def build_runner(algo_observer):\n",
    "    runner = Runner(algo_observer)\n",
    "    runner.player_factory.register_builder(\n",
    "        'a2c_continuous', lambda **kwargs : common_player.CommonPlayer(**kwargs)\n",
    "    )\n",
    "    return runner\n",
    "        \n",
    "# register the rl-games adapter to use inside the runner\n",
    "vecenv.register('RLGPU',\n",
    "                lambda config_name, num_actors, **kwargs: RLGPUEnv(config_name, num_actors, **kwargs))\n",
    "env_configurations.register('rlgpu', {\n",
    "    'vecenv_type': 'RLGPU',\n",
    "    'env_creator': create_env_thunk,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622ea946-ac81-4764-b49a-4e821ecd1794",
   "metadata": {},
   "source": [
    "## Create runner and player (agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "754d24c5-dd30-43dd-b481-897156d446ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T14:38:05.008774Z",
     "iopub.status.busy": "2022-07-14T14:38:05.008565Z",
     "iopub.status.idle": "2022-07-14T14:38:05.021578Z",
     "shell.execute_reply": "2022-07-14T14:38:05.021008Z",
     "shell.execute_reply.started": "2022-07-14T14:38:05.008753Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.seed = 42\n"
     ]
    }
   ],
   "source": [
    "runner = build_runner(RLGPUTaskAlgoObserver())\n",
    "rlg_config_dict = omegaconf_to_dict(cfg.train)\n",
    "runner.load(rlg_config_dict)\n",
    "runner.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da828ea7-ec6c-4595-8256-78e0a0576e15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-14T14:38:05.022379Z",
     "iopub.status.busy": "2022-07-14T14:38:05.022172Z",
     "iopub.status.idle": "2022-07-14T14:38:30.695575Z",
     "shell.execute_reply": "2022-07-14T14:38:30.694388Z",
     "shell.execute_reply.started": "2022-07-14T14:38:05.022354Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs type: full\n",
      "[Warning] [carb.gym.plugin] useGpu is set, forcing single scene (0 subscenes)\n",
      "Not connected to PVD\n",
      "+++ Using GPU PhysX\n",
      "Physics Engine: PhysX\n",
      "Physics Device: cuda:0\n",
      "GPU Pipeline: enabled\n",
      "Num hand dofs:  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scr1/.pyenv/versions/miniconda3-latest/envs/rlgpu/lib/python3.7/site-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "Num dofs:  19\n",
      "{'observation_space': Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf], (72,), float32), 'action_space': Box([-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (17,), float32), 'agents': 1, 'value_size': 1}\n",
      "build mlp: 72\n",
      "RunningMeanStd:  (1,)\n",
      "RunningMeanStd:  (72,)\n",
      "=> loading checkpoint './runs/scaled-ac/nn/scaled-ac.pth'\n",
      "reward: 149346.375 steps: 600.0\n",
      "9558168.0\n",
      "av reward: 149346.375 av steps: 600.0\n"
     ]
    }
   ],
   "source": [
    "agent = runner.create_player()\n",
    "\n",
    "agent.restore(cfg.checkpoint)\n",
    "\n",
    "agent.games_num = agent.env.num_environments\n",
    "\n",
    "agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8343b720-699d-4c63-b982-2b41ba615e6d",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-07-14T14:09:28.554042Z",
     "iopub.status.busy": "2022-07-14T14:09:28.553654Z",
     "iopub.status.idle": "2022-07-14T14:16:05.181653Z",
     "shell.execute_reply": "2022-07-14T14:16:05.180831Z",
     "shell.execute_reply.started": "2022-07-14T14:09:28.553996Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started to play\n",
      "Obs type: full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scr1/.pyenv/versions/miniconda3-latest/envs/rlgpu/lib/python3.7/site-packages/gym/spaces/box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] [carb.gym.plugin] useGpu is set, forcing single scene (0 subscenes)\n",
      "Not connected to PVD\n",
      "+++ Using GPU PhysX\n",
      "Physics Engine: PhysX\n",
      "Physics Device: cuda:0\n",
      "GPU Pipeline: enabled\n",
      "Num hand dofs:  17\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "[Warning] [carb.gym.plugin] User aggregate size exceeded\n",
      "Num dofs:  19\n",
      "{'observation_space': Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
      " -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf], (72,), float32), 'action_space': Box([-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], (17,), float32), 'agents': 1, 'value_size': 1}\n",
      "build mlp: 72\n",
      "RunningMeanStd:  (1,)\n",
      "RunningMeanStd:  (72,)\n",
      "=> loading checkpoint './runs/scaled-ac/nn/scaled-ac.pth'\n",
      "reward: 149369.265625 steps: 600.0\n",
      "reward: 149311.09375 steps: 600.0\n",
      "reward: 149241.359375 steps: 600.0\n",
      "reward: 149223.828125 steps: 600.0\n",
      "reward: 149256.796875 steps: 600.0\n",
      "reward: 149235.921875 steps: 600.0\n",
      "reward: 149284.0 steps: 600.0\n",
      "reward: 149240.9375 steps: 600.0\n",
      "reward: 149224.6875 steps: 600.0\n",
      "reward: 149242.0 steps: 600.0\n",
      "reward: 149340.265625 steps: 600.0\n",
      "reward: 149188.65625 steps: 600.0\n",
      "reward: 149290.0625 steps: 600.0\n",
      "reward: 149271.78125 steps: 600.0\n",
      "reward: 149249.21875 steps: 600.0\n",
      "reward: 149239.65625 steps: 600.0\n",
      "reward: 36745.88671875 steps: 148.0\n",
      "reward: 245.83204650878906 steps: 1.0\n",
      "reward: 245.6247100830078 steps: 1.0\n",
      "reward: 245.5674285888672 steps: 1.0\n",
      "reward: 245.5299530029297 steps: 1.0\n",
      "reward: 245.51644897460938 steps: 1.0\n",
      "reward: 245.50340270996094 steps: 1.0\n",
      "reward: 245.4850311279297 steps: 1.0\n",
      "reward: 245.46377563476562 steps: 1.0\n",
      "reward: 245.4418487548828 steps: 1.0\n",
      "reward: 245.41317749023438 steps: 1.0\n",
      "reward: 245.37957763671875 steps: 1.0\n",
      "reward: 245.35655212402344 steps: 1.0\n",
      "reward: 245.33421325683594 steps: 1.0\n",
      "reward: 245.30909729003906 steps: 1.0\n",
      "reward: 245.2770233154297 steps: 1.0\n",
      "reward: 245.25408935546875 steps: 1.0\n",
      "reward: 245.2472686767578 steps: 1.0\n",
      "reward: 245.24522399902344 steps: 1.0\n",
      "reward: 245.2501678466797 steps: 1.0\n",
      "reward: 245.26402282714844 steps: 1.0\n",
      "reward: 245.27667236328125 steps: 1.0\n",
      "reward: 245.2822265625 steps: 1.0\n",
      "reward: 245.28228759765625 steps: 1.0\n",
      "reward: 245.27633666992188 steps: 1.0\n",
      "reward: 245.2627716064453 steps: 1.0\n",
      "reward: 245.25192260742188 steps: 1.0\n",
      "reward: 245.2514190673828 steps: 1.0\n",
      "reward: 245.25950622558594 steps: 1.0\n",
      "reward: 245.25926208496094 steps: 1.0\n",
      "reward: 245.252685546875 steps: 1.0\n",
      "reward: 245.25343322753906 steps: 1.0\n",
      "reward: 245.25315856933594 steps: 1.0\n",
      "reward: 245.25315856933594 steps: 1.0\n",
      "reward: 245.25311279296875 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25315856933594 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25315856933594 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25315856933594 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25315856933594 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 245.2531280517578 steps: 1.0\n",
      "reward: 245.25314331054688 steps: 1.0\n",
      "reward: 146974.984375 steps: 590.640625\n",
      "reward: 149194.484375 steps: 600.0\n",
      "reward: 149282.421875 steps: 600.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/user/18784/ipykernel_946476/714701946.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                  \u001b[0;34m\"play\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  \u001b[0;34m\"checkpoint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                  \"sigma\": None})\n\u001b[0m",
      "\u001b[0;32m/scr-ssd/ksrini/libs/rl_games/rl_games/torch_runner.py\u001b[0m in \u001b[0;36mrun_play\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0m_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0m_override_sigma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mplayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_player\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scr-ssd/ksrini/libs/IsaacGymEnvs/isaacgymenvs/learning/common_player.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_determenistic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                 \u001b[0mobs_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0mcr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0msteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scr-ssd/ksrini/libs/rl_games/rl_games/common/player.py\u001b[0m in \u001b[0;36menv_step\u001b[0;34m(self, env, actions)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor_obses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dtype'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scr-ssd/ksrini/libs/IsaacGymEnvs/isaacgymenvs/tasks/base/vec_task.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_render\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# to fix!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runner.run_play({\"train\": False,\n",
    "                 \"play\": True,\n",
    "                 \"checkpoint\": cfg.checkpoint,\n",
    "                 \"sigma\": None})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6643df-2a7c-4413-b038-0c68c896a9f3",
   "metadata": {},
   "source": [
    "## Test run one step\n",
    "```python\n",
    "obs = agent.env_reset(agent.env)\n",
    "batch_size = agent.get_batch_size(obs['obs'], 1)\n",
    "actions = agent.get_action(agent.obs_to_torch(obs))\n",
    "obses, r, done, info = agent.env_step(agent.env, actions)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlgpu",
   "language": "python",
   "name": "rlgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
